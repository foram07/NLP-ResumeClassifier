{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Reference: https://www.kaggle.com/datasets/gauravduttakiit/resume-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Java Developer               84\n",
       "Testing                      70\n",
       "DevOps Engineer              55\n",
       "Python Developer             48\n",
       "Web Designing                45\n",
       "HR                           44\n",
       "Hadoop                       42\n",
       "Blockchain                   40\n",
       "ETL Developer                40\n",
       "Operations Manager           40\n",
       "Data Science                 40\n",
       "Sales                        40\n",
       "Mechanical Engineer          40\n",
       "Arts                         36\n",
       "Database                     33\n",
       "Electrical Engineering       30\n",
       "Health and fitness           30\n",
       "PMO                          30\n",
       "Business Analyst             28\n",
       "DotNet Developer             28\n",
       "Automation Testing           26\n",
       "Network Security Engineer    25\n",
       "SAP Developer                24\n",
       "Civil Engineer               24\n",
       "Advocate                     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Classes (Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Category Distribution (After Oversampling):\n",
      "Category\n",
      "Python Developer             84\n",
      "Mechanical Engineer          84\n",
      "PMO                          84\n",
      "Sales                        84\n",
      "SAP Developer                84\n",
      "Advocate                     84\n",
      "Web Designing                84\n",
      "ETL Developer                84\n",
      "Electrical Engineering       84\n",
      "Arts                         84\n",
      "Hadoop                       84\n",
      "DotNet Developer             84\n",
      "Testing                      84\n",
      "Java Developer               84\n",
      "Civil Engineer               84\n",
      "HR                           84\n",
      "Blockchain                   84\n",
      "Automation Testing           84\n",
      "Network Security Engineer    84\n",
      "Business Analyst             84\n",
      "Health and fitness           84\n",
      "DevOps Engineer              84\n",
      "Database                     84\n",
      "Data Science                 84\n",
      "Operations Manager           84\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/4178086278.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Get the largest category size (i.e., the category with the maximum number of entries)\n",
    "max_size = df['Category'].value_counts().max()\n",
    "\n",
    "# Perform oversampling\n",
    "balanced_df = df.groupby('Category').apply(lambda x: x.sample(max_size, replace=True)).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the dataset to avoid any order bias\n",
    "df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check the balanced category distribution\n",
    "print(\"\\nBalanced Category Distribution (After Oversampling):\")\n",
    "print(df['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data:\n",
    "1 URLs,\n",
    "2 hashtags,\n",
    "3 mentions,\n",
    "4 special letters,\n",
    "5 punctuations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/3739445999.py:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/3739445999.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/3739445999.py:6: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  cleanText = re.sub('@\\S+', '  ', cleanText)\n",
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/3739445999.py:7: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
      "/var/folders/__/pqnc_9wj0dl16l1pnxmqq81c0000gp/T/ipykernel_77891/3739445999.py:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  cleanText = re.sub('\\s+', ' ', cleanText)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)  \n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText) \n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resume'] = df['Resume'].apply(lambda x: cleanResume(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder: words into categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 15,  6,  7,  8, 14,  4, 17,  2,  3, 12,  5, 23, 16,  9, 13,  1,\n",
       "       11, 10, 24,  0, 21, 22, 19, 18])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df['Category'])\n",
    "df['Category'] = le.transform(df['Category'])\n",
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf.fit(df['Resume'])\n",
    "requiredText  = tfidf.transform(df['Resume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(requiredText, df['Category'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let’s train the model and print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNeighborsClassifier Results:\n",
      "Accuracy: 0.9952\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0 13  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        17\n",
      "           5       1.00      1.00      1.00        19\n",
      "           6       1.00      1.00      1.00        19\n",
      "           7       1.00      1.00      1.00        11\n",
      "           8       1.00      0.87      0.93        15\n",
      "           9       0.90      1.00      0.95        18\n",
      "          10       1.00      1.00      1.00        19\n",
      "          11       1.00      1.00      1.00        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        27\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       1.00      1.00      1.00        18\n",
      "          16       1.00      1.00      1.00        12\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       1.00      1.00      1.00        14\n",
      "          19       1.00      1.00      1.00        20\n",
      "          20       1.00      1.00      1.00        15\n",
      "          21       1.00      1.00      1.00        16\n",
      "          22       1.00      1.00      1.00        10\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00       420\n",
      "   macro avg       1.00      0.99      1.00       420\n",
      "weighted avg       1.00      1.00      1.00       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Ensure that X_train and X_test are dense if they are sparse\n",
    "X_train = X_train.toarray() if hasattr(X_train, 'toarray') else X_train\n",
    "X_test = X_test.toarray() if hasattr(X_test, 'toarray') else X_test\n",
    "\n",
    "# 1. Train KNeighborsClassifier\n",
    "knn_model = OneVsRestClassifier(KNeighborsClassifier())\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "print(\"\\nKNeighborsClassifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_knn)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_knn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Results:\n",
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        17\n",
      "           5       1.00      1.00      1.00        19\n",
      "           6       1.00      1.00      1.00        19\n",
      "           7       1.00      1.00      1.00        11\n",
      "           8       1.00      1.00      1.00        15\n",
      "           9       1.00      1.00      1.00        18\n",
      "          10       1.00      1.00      1.00        19\n",
      "          11       1.00      1.00      1.00        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        27\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       1.00      1.00      1.00        18\n",
      "          16       1.00      1.00      1.00        12\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       1.00      1.00      1.00        14\n",
      "          19       1.00      1.00      1.00        20\n",
      "          20       1.00      1.00      1.00        15\n",
      "          21       1.00      1.00      1.00        16\n",
      "          22       1.00      1.00      1.00        10\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00       420\n",
      "   macro avg       1.00      1.00      1.00       420\n",
      "weighted avg       1.00      1.00      1.00       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Train SVC\n",
    "svc_model = OneVsRestClassifier(SVC())\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "print(\"\\nSVC Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svc):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svc)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestClassifier Results:\n",
      "Accuracy: 1.0000\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  20]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        17\n",
      "           5       1.00      1.00      1.00        19\n",
      "           6       1.00      1.00      1.00        19\n",
      "           7       1.00      1.00      1.00        11\n",
      "           8       1.00      1.00      1.00        15\n",
      "           9       1.00      1.00      1.00        18\n",
      "          10       1.00      1.00      1.00        19\n",
      "          11       1.00      1.00      1.00        16\n",
      "          12       1.00      1.00      1.00        16\n",
      "          13       1.00      1.00      1.00        27\n",
      "          14       1.00      1.00      1.00        22\n",
      "          15       1.00      1.00      1.00        18\n",
      "          16       1.00      1.00      1.00        12\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       1.00      1.00      1.00        14\n",
      "          19       1.00      1.00      1.00        20\n",
      "          20       1.00      1.00      1.00        15\n",
      "          21       1.00      1.00      1.00        16\n",
      "          22       1.00      1.00      1.00        10\n",
      "          23       1.00      1.00      1.00        16\n",
      "          24       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00       420\n",
      "   macro avg       1.00      1.00      1.00       420\n",
      "weighted avg       1.00      1.00      1.00       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Train RandomForestClassifier\n",
    "rf_model = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\nRandomForestClassifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
    "pickle.dump(svc_model, open('clf.pkl', 'wb'))\n",
    "pickle.dump(le, open(\"encoder.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the category of a resume\n",
    "def pred(input_resume):\n",
    "    # Preprocess the input text (e.g., cleaning, etc.)\n",
    "    cleaned_text = cleanResume(input_resume) \n",
    "\n",
    "    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training\n",
    "    vectorized_text = tfidf.transform([cleaned_text])\n",
    "    \n",
    "    # Convert sparse matrix to dense\n",
    "    vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "    # Prediction\n",
    "    predicted_category = svc_model.predict(vectorized_text)\n",
    "\n",
    "    # get name of predicted category\n",
    "    predicted_category_name = le.inverse_transform(predicted_category)\n",
    "\n",
    "    return predicted_category_name[0]  # Return the category name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Science'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myresume = \"\"\"I am a data scientist specializing in machine\n",
    "learning, deep learning, and computer vision. With\n",
    "a strong background in mathematics, statistics,\n",
    "and programming, I am passionate about\n",
    "uncovering hidden patterns and insights in data.\n",
    "I have extensive experience in developing\n",
    "predictive models, implementing deep learning\n",
    "algorithms, and designing computer vision\n",
    "systems. My technical skills include proficiency in\n",
    "Python, Sklearn, TensorFlow, and PyTorch.\n",
    "What sets me apart is my ability to effectively\n",
    "communicate complex concepts to diverse\n",
    "audiences. I excel in translating technical insights\n",
    "into actionable recommendations that drive\n",
    "informed decision-making.\n",
    "If you're looking for a dedicated and versatile data\n",
    "scientist to collaborate on impactful projects, I am\n",
    "eager to contribute my expertise. Let's harness the\n",
    "power of data together to unlock new possibilities\n",
    "and shape a better future.\n",
    "Contact & Sources\n",
    "Email: 611noorsaeed@gmail.com\n",
    "Phone: 03442826192\n",
    "Github: https://github.com/611noorsaeed\n",
    "Linkdin: https://www.linkedin.com/in/noor-saeed654a23263/\n",
    "Blogs: https://medium.com/@611noorsaeed\n",
    "Youtube: Artificial Intelligence\n",
    "ABOUT ME\n",
    "WORK EXPERIENCE\n",
    "SKILLES\n",
    "NOOR SAEED\n",
    "LANGUAGES\n",
    "English\n",
    "Urdu\n",
    "Hindi\n",
    "I am a versatile data scientist with expertise in a wide\n",
    "range of projects, including machine learning,\n",
    "recommendation systems, deep learning, and computer\n",
    "vision. Throughout my career, I have successfully\n",
    "developed and deployed various machine learning models\n",
    "to solve complex problems and drive data-driven\n",
    "decision-making\n",
    "Machine Learnine\n",
    "Deep Learning\n",
    "Computer Vision\n",
    "Recommendation Systems\n",
    "Data Visualization\n",
    "Programming Languages (Python, SQL)\n",
    "Data Preprocessing and Feature Engineering\n",
    "Model Evaluation and Deployment\n",
    "Statistical Analysis\n",
    "Communication and Collaboration\n",
    "\"\"\"\n",
    "\n",
    "pred(myresume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
